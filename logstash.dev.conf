input {
	file {
        add_field => [ 'app', 'app-dev' ]
        add_field => [ 'module', 'app' ]
        path => '/app/app.log'
        type => 'webapp'
        codec => multiline {
        pattern => "(^\d+\serror)|(^.+Exception: .+)|(^\s+at .+)|(^\s+... \d+ more)|(^\s*Caused by:.+)(^\s*Unable to get response from ABC Microservice:.+)"
        what => "previous"
        max_lines => 500
        }
	}
}

filter {
    grok {
        patterns_dir => ["/opt/logstash/patterns"]
        match => ["message", "%{DATE} %{TIME},%{INT} %{LOGLEVEL:loglevel} .* - RequestLog : %{GREEDYDATA:requestData}" ]
       remove_tag => ["_grokparsefailure"]
	}
	  
    json {
        source =>requestData
    }
    
     if "_grokparsefailure" in [tags] {
	    grok {
	      patterns_dir => ["/opt/logstash/patterns"]
	      # check if the log line contains a date
	      match => { "message" => "%{CUSTOM_MICROSERVICE_EXCEPTION:exceptionByMicroservice} %{GREEDYDATA:messageText}" }
	      match => { "message" => "%{CUSTOM_MICROSERVICE_EXCEPTION:exceptionByMicroservice}" }
	      remove_tag => ["_grokparsefailure"]
    	}
    }
    if "_grokparsefailure" in [tags] {
     grok {
      patterns_dir => ["/opt/logstash/patterns"]
      # check if the log line contains a date
      match => { "message" => "%{CUSTOM_CATALINALOG:catalinaLog}" }
      add_field => { "subType" => "timestamp" }
      remove_tag => ["_grokparsefailure"]
    }
    }
    if "_grokparsefailure" in [tags] {
      grok {
        patterns_dir => ["/opt/logstash/patterns"]
        # check if the log line is has 'caused by'
        match => { "message" => "%{CUSTOM_TRACE_CAUSED_BY:causedbyText} %{GREEDYDATA:messageText}" }
        add_field => { "subType" => "cause" }
        remove_tag => ["_grokparsefailure"]
      }
    }
    if "_grokparsefailure" in [tags] {
      grok {
        patterns_dir => ["/opt/logstash/patterns"]
        # check if the log line is an error trace
        match => { "message" => "%{CUSTOM_TRACE_ERROR:errorTrace} %{GREEDYDATA:messageText}" }
        add_field => { "subType" => "errorTrace" }
        remove_tag => ["_grokparsefailure"]
      }
    }
    if "_grokparsefailure" in [tags] {
      grok {
        patterns_dir => ["/opt/logstash/patterns"]
        # check if the log line is a message
        match => { "message" => "%{CUSTOM_WARNINGLEVEL:warningLevel} %{GREEDYDATA:messageText}" }
        add_field => { "subType" => "warning" }
        remove_tag => ["_grokparsefailure"]
      }
    }
    if "_grokparsefailure" in [tags] {
      grok {
        patterns_dir => ["/opt/logstash/patterns"]
        # check if the log line is an exception
        match => { "message" => "%{CUSTOM_TRACE_EXCEPTION:exceptionText} %{GREEDYDATA:messageText}" }
        match => { "message" => "%{CUSTOM_TRACE_EXCEPTION:exceptionText}" }
        add_field => { "subType" => "exception" }
        remove_tag => ["_grokparsefailure"]
      }
    }
    if "_grokparsefailure" in [tags] {
      grok {
        patterns_dir => ["/opt/logstash/patterns"]
        # check if the log line is part of earlier 'exception' or 'caused by'
        match => { "message" => "%{CUSTOM_TRACE_OTHERS:messageText}" }
        add_field => { "subType" => "continuation" }
        remove_tag => ["_grokparsefailure"]
      }
    }
    
    if "_grokparsefailure" in [tags] {
      grok {
        patterns_dir => ["/opt/logstash/patterns"]
        # parse all other lines as 'unrecognizedText' so that it is not lost after parsing
        match => { "message" => "%{GREEDYDATA:unrecognizedText}" }
        add_field => { "subType" => "unrecognizedText" }
        remove_tag => ["_grokparsefailure"]
      }
    }
    
    mutate {
      gsub => ['message', "\t", " "]
      gsub => ['catalinaLog', "\t", " "]
      gsub => ['messageText', "\t", " "]
      gsub => ['exceptionText', "\t", " "]
      gsub => ['errorTrace', "\t", " "]
      gsub => ['unrecognizedText', "\t", " "]
      gsub => ['exceptionByMicroservice', "\t", " "]
    }
    ruby {
      code => "event['upload_time'] = event['@timestamp']"
    }
    mutate {
      add_field => ["upload_time_string", "%{@timestamp}"]
    }
  
    
}

output {
    elasticsearch {
        hosts => ["ELASTICSEARCHURL"]
        ssl => true
        user => "<USERNAME>"
        password =>"<PASSWORD>"
        index => "app-dev-%{+YYYY.MM.dd}"
        flush_size => 1
    }
}

